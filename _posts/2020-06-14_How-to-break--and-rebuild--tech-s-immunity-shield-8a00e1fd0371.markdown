---
title: How to break (and rebuild) tech’s immunity shield
description: >-
  On June 4th, 2020 President Trump signed an Executive Order to break the
  immunity shield behind Section 230. This section has been called…
date: '2020-06-14T16:34:52.929Z'
categories: []
keywords: []
slug: /@andrescrucetta/how-to-break-and-rebuild-techs-immunity-shield-8a00e1fd0371
category: 'article'
layout: post
---

![](/Users/andrescrucettanieto/Documents/GitHub/markdown-converter/posts/md_1672369357164/img/0__ThratdTHRDveAq__3.jpg)

On June 4th, 2020 President Trump signed an Executive Order to break the immunity shield behind Section 230. This section has been called the “twenty-six words that created the internet”. It protects social media giants such as Twitter and Facebook from liability for any content posted on their websites.1

![](/Users/andrescrucettanieto/Documents/GitHub/markdown-converter/posts/md_1672369357164/img/0__r4oMmrT71AlwPava.jpg)

Basically, no social media platform (e.g., Twitter), or internet forum (e.g., Reddit), should be liable for any information on their platforms. Proponents hail it as the “freedom of speech” amendment for the internet.2 They say without it, many forums wouldn’t have flourished.

The section, however, is notoriously polemic. Both republicans and democrats argue it doesn’t enforce enough pressure on tech companies to moderate the content posted on their platforms. Research states that at least 1 in 5 people who use the internet has been the victim of hurting comments, or worse, inflammatory pictures or videos posted without their consent. Minorities, such as Latinos, African-American, and the LGBTQ community historically suffering the majority of these attacks.3

### **Where does Section 230 come from?**

In 1996, members of congress wanted to adapt the legislature to put a check on the ever-evolving technologies. They sought to preserve the freedom of the internet, which society has benefited from, while also protecting people from illegal posts and offensive material. Federal agencies wouldn’t be able to filter all of the information posted on Facebook or Twitter. Thus, they came up with an incentive for “Good Samaritans”, platforms that did their “best” to protect users from misinformation and illegal material.

Leading to the Communications Decency Act (CDA), part of the Telecommunications Act of 1996. Its goal was to make the internet a safe place for all users. Its creators understood the need to use the private sector as their own censors, hence, they enacted within the CDA an amendment called “Protection for Private Blocking and Screening of Offensive Material”. Section 230 was born.

This amendment provided a figurative immunity shield to companies that did their best to filter objectionable content. This hall pass wouldn’t apply to violations of federal criminal law, intellectual property law, or the facilitation of sex trafficking. It would apply to tweets such as President Trump’s “When the looting starts, the shooting starts”.

### **Why is it so complicated to change it?**

Section 230 is complicated due to the many misconceptions within it: is the debate about freedom of speech, or is it about who does the censoring. Technology has historically been a hard issue to regulate because of the technical knowledge required to grasp it. As seen during Mark Zuckerberg’s Senate hearing, some senators struggled to even grasp Facebook’s revenue model, if it’s free, how do you make money again?.4

**Is the internet “speech”?**

As it stands now, Section 230 assumes everything on the internet is speech. In 1996 when the law was enacted, only 20 million Americans had access to it. Now, there are over 293 million users connected to it.5 People are using it for buying, selling, posting, sharing, finding dates, making reservations, reading books, and looking for jobs. Without any major changes since 1996, the law still considers all of these uses as speech.

**Do internet platforms have to be neutral?**

A major misconception is that, for internet companies to keep their immunity shield, they should be “neutral public forums”. Thinking, if they remove, block, or mute user-content based on its point of view it would revoke their protection against lawsuits.

However, nothing in the text of Section 230 nor in its history of lawsuits supports this. The statute doesn’t require them to act neutrally, rather, it urges them to “develop blocking and filtering technology”.

This misconception also ignores the fact that the first amendment’s free speech regulation applies only to government actors, not to private ones. Therefore, private companies, such as Twitter, Facebook, and Snap are not bound to it.

### **What can we change?**

The first solution would be to replace the word “information” in section 230 with the word **speech.** That is:

_No provider or user of an interactive computer service shall be treated as the publisher or speaker of any_ **_speech_** _provided by another information content provider._

Professor Danielle Citron from Boston University says, if a platform cannot make the argument that what users are posting is “speech” then it should not be protected by section 230’s immunity shield. 6

The second solution is to exclude “bad samaritans” or platforms who “deliberately leave up ambiguously unlawful content that clearly creates serious harm to others.” 7. This change would preserve the immunity of platforms that do their best effort to control unlawful content while holding accountable companies who take advantage of the law.

The final solution is to condition the legal shield to platforms that have “good enough” content moderation. This law would require first defining what’s good enough. Secondly, it would require prosecutors to examine the platform’s filters — something that requires technical knowledge and time. This solution, however, wouldn’t provide enough coverage for most cases.

An example of how this third solution would play out in real life is if a user was publicly shamed and took Facebook to court. He or she would argue the platform could have done a better job at removing the post. Facebook would argue that they employ moderators that remove the content within a week. By doing so, they would be protected by the law. The problem behind this solution is that companies are only held accountable to provide “reasonable practices writ at large”, leaving millions of people still at risk.

While Section 230 is hailed as the bedrock of the internet it has had its fair share of controversy. In order for the internet to remain a place for safe public discourse, we must put a check on bad actors, define what constitutes speech within it, and improve content quality standards. As Jimmy Carter said, “We must adjust to changing times and still hold to unchanging principles”.

**References:**

1.  Kosseff, n.d.
2.  Written Testimony of Danielle Keats Citron before House Energy and Commerce Committee in “Fostering a Healthier Internet to Protect Consumers” hearing (October 16, 2019), available at, [https://docs.house.gov/meetings/IF/IF16/20191016/110075/HHRG-116-IF16-Wstate-CitronD-](https://docs.house.gov/meetings/IF/IF16/20191016/110075/HHRG-116-IF16-Wstate-CitronD-) 20191016.pdf.
3.  CITRON, HATE CRIMES IN CYBERSPACE, supra note.
4.  [https://money.cnn.com/2018/04/10/technology/senate-mark-zuckerberg-testimony/index.html](https://money.cnn.com/2018/04/10/technology/senate-mark-zuckerberg-testimony/index.html)
5.  J. Clement, Internet usage in the United States — Statistics & Facts, Statista (Aug. 20, 2019) [https://www.statista.com/topics/2237/internet-usage-in-the-united-states/](https://www.statista.com/topics/2237/internet-usage-in-the-united-states/).
6.  Danielle Keats Citron, Cyber Civil Rights, 89 B.U. L. Rev. 61, 99 (2009).
7.  Amicus Curiae of Cyber Civil Right Initiative