I"É<p>Recently, I finished the ‚ÄúWriting an Interpreter in Go‚Äù. As I started reading the sequel, I found myself puzzled by the shift from interpreting source code to compiling it into code for virtual machines. This prompted me to understand the concept of compilers, Bytecode, and the reasons behind its efficiency.</p>

<p>In the first book, the workflow was straightforward:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Source Code
|
| (Lexer)
v
Tokens
|
| (Parser)
v
Abstract Syntax Tree (AST)
|
| (Evaluator)
v
Output
</code></pre></div></div>

<p>The Lexer transforms the source code into tokens. These tokens are then parsed into an Abstract Syntax Tree (AST) based on predefined rules, and subsequently evaluated to produce the final output.</p>

<p>However, in the sequel, the workflow takes a different turn:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Source Code
|
| (Lexer)
v
Tokens
|
| (Parser)
v
Abstract Syntax Tree (AST)
|
| (Compiler)
v
Bytecode
|
| (Virtual Machine)
v
Output
</code></pre></div></div>

<p>In this new workflow, the AST is compiled into Bytecode instead of being directly evaluated. The Bytecode is then executed to produce the output.</p>

<p>Let‚Äôs take an example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Source Code:

def add(a, b):
return a+b
AST:

FunctionDef
|-- name: "add"
|-- args: Arguments
| |-- args: ["a", "b"]
|-- body: Return
|-- value: BinOp
|-- left: "a"
|-- op: Add
|-- right: "b"
</code></pre></div></div>

<p>This is then converted into Bytecode:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LOAD_FAST 0
LOAD_FAST 1
BINARY_ADD
RETURN_VALUE
</code></pre></div></div>

<p>Finally, the virtual machine translates this into:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mov eax, [ebp+8]
add eax, [ebp+12]
ret
</code></pre></div></div>

<p>This final form may seem like an alien language to the uninitiated, but it‚Äôs the language our hardware understands and executes.</p>

<h2 id="the-rationale-behind-bytecode">The Rationale Behind Bytecode</h2>

<p>The book cites efficiency, portability, and optimization as the primary reasons for this conversion to Bytecode.</p>

<h3 id="efficiency-streamlining-functions">Efficiency: Streamlining Functions</h3>

<p>Bytecode, being more compact and faster to decode than high-level source code, allows virtual machines to execute it more rapidly than an interpreter can execute source code.</p>

<p>Consider this factorial function:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def factorial(n):
  if n == 0:
    return 1
  else:
    return n \* factorial(n-1)
</code></pre></div></div>

<p>When compiled to Bytecode, it becomes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 LOAD_FAST 0 (n)
3 LOAD_CONST 1 (0)
6 COMPARE_OP 2 (==)
9 POP_JUMP_IF_FALSE 16
12 LOAD_CONST 2 (1)
15 RETURN_VALUE
16 LOAD_FAST 0 (n)
19 LOAD_FAST 0 (n)
22 LOAD_CONST 3 (1)
25 BINARY_SUBTRACT
26 CALL_FUNCTION 1
29 BINARY_MULTIPLY
30 RETURN_VALUE
</code></pre></div></div>

<p>This Bytecode is more efficient because it transforms the recursive function into a loop, reducing the overhead of creating a new stack frame with each recursion.</p>

<h3 id="portability">Portability</h3>

<p>Bytecode can be interpreted by any virtual machine, enhancing its portability. For instance, in Java, the Java Virtual Machine (JVM) executes the .class files, which are Bytecode, making Java programs platform-independent.</p>

<h3 id="optimization-opportunities">Optimization Opportunities</h3>

<p>Bytecode offers opportunities for both compile-time and run-time optimizations.</p>

<h4 id="compile-time-optimization">Compile-Time Optimization</h4>

<p>Compile-time optimization occurs when the code is converted to Bytecode. For instance, consider this C code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>int x = 5;
int y = x \* 10;
</code></pre></div></div>

<p>Since x is a constant, we can directly store the final result in the Bytecode:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>int x = 5;
int y = 50;
</code></pre></div></div>

<h4 id="run-time-optimization">Run-Time Optimization</h4>

<p>Run-time optimization involves ‚ÄúJust-In-Time‚Äù (JIT) compilation, which compiles parts of the program during execution. This approach is different from the traditional ‚Äúahead of time‚Äù compilation (as in C) or line-by-line interpretation (as in Python).</p>

<p>JIT compilation profiles the code during its conversion to Bytecode, identifying ‚Äúhot spots‚Äù - areas that are frequently executed or time-consuming. These hot spots are then converted into machine code specific to the hardware being used. This machine code is stored in a cache and can be reused whenever the code is executed again, improving performance.</p>

<p>In the next installment of this compiler series, I‚Äôm going to explore the different types of machine codes. I‚Äôll also explore the differences in compiling functional languages (like O‚ÄôCaml) versus multi-paradigm languages (like Python).</p>
:ET