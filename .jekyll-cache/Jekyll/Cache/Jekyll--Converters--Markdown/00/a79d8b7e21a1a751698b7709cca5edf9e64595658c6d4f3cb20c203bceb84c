I"û<p>It can be hard to make decisions at a startup. Things change, and the tools you choose today may not work tomorrow.¬†</p>

<p>When I first joined my startup, I was thrown into a messy codebase written by offshore contractors. We were using 50+ Postgres stored procedures without version control. We had over 200 Azure Data Factory pipelines but only used about a dozen. It was a nightmare.</p>

<p>I spent months wrestling with these tools, only to learn there was no incentive to change them at the time. We had to wait for a new window of opportunity to improve things. It was a harsh lesson as a young developer: you can‚Äôt always change tools mid-project. Sometimes, you have to make do with what you have.</p>

<h2 id="i-dealing-with-changing-requirements">I. Dealing with changing requirements</h2>

<p>When we launched our first product, it didn‚Äôt make enough money. So, we had to pivot to a new idea. This allowed us to improve our architecture.</p>

<p>Initially, we thought we would use unstructured data, so we chose Elastic Search, a NoSQL database used for text search. We built all of our production APIs around it. But, as we learned more about the data, we realized our structure needed to be simplified. We merged many SQL tables into a massive JSON document, which we queried from Elastic.</p>

<p>Once we recognized our mistake, we reverted to structured data, splitting the JSON document into multiple tables. Although a traditional SQL database was better, we had built all our APIs around it. Making it hard to switch.</p>

<p>This taught me that while it‚Äôs essential to adapt to changing requirements, it‚Äôs crucial to consider the long-term impact of architectural decisions. Some tools APIs, like Elastic, can be harder to change than if we had gone with a more flexible database like Postgres or Snowflake.</p>

<h2 id="ii-refactoring-vs-new-tools">II. Refactoring vs. New Tools</h2>

<p>Our data team faced a similar issue. We needed version control for our offshore team‚Äôs work. I suggested we move to DBT and Airflow for version control. We eventually adopted DBT but stuck with Azure Data Factory.</p>

<p>Our initial experience with Azure Data Factory was frustrating because of poorly structured code. But we realized the tool wasn‚Äôt the problem; it was how we used it.¬†</p>

<p>We chose to refactor our code and make better use of ADF. Moving to DBT early in the product launch was a good decision since we could start fresh. But with ADF, we had to improve what we had.</p>

<p>This taught me a crucial lesson: sometimes, it‚Äôs better to refactor and optimize existing tools rather than switch to new ones.</p>

<h2 id="iii-focus-on-shipping-features">III. Focus on shipping features</h2>

<p>Over the past two years, I‚Äôve realized that if you‚Äôre building a startup, you can‚Äôt spend too much time debating what tools to use or constantly refactoring your codebase. It‚Äôs almost always better to focus on shipping new features and taking advantage of newer projects to introduce new tools.¬†</p>

<p>Most clients don‚Äôt care if you‚Äôre running on the ‚Äúmodern data stack.‚Äù They care the product works. Even though it‚Äôs easy to fall in love with tools as developers, tools by themselves are not a panacea.</p>

<p>This is a harsh lesson to learn, but it gives you the freedom to spend the time solving the problems that matter. Tools are essential, but the real value lies in solving problems for the people paying you.</p>

:ET